\input{_header.tex}

% SET_DEFAULTS
%   GG-WIDTH: 4  GG-HEIGHT: 4
%   TEX-WIDTH: 0.5\textwidth
%   INLINE: FALSE
% 

% END

\chapter{Toolbox}
\label{cha:toolbox}

\section{Introduction}

The use of layers in \ggplot, introduced in the preceding chapter, encourages you to design and construct graphics in a structured manner.  You have learned what a layer is and how to add one to your graphic, but not what geoms and statistics are available to help you build revealing plots.  This chapter lists the many geoms and stats included in \ggplot, broken down by their purpose.  The main purpose of this chapter is to provide a good overview of the available options: it does not describe each geom and stat in detail.  For more information about individual geoms, along with many more examples showing how you can use it, see the online and electronic documentation.

To illustrate the geoms a wide range of datasets is used.  You have seen each of them before, but the list below should refresh your memory about the major features of each dataset.  Remember you can find out more details with the online documentation.

\begin{itemize}
  \item The diamonds data contains 50,000 round cut diamonds
\end{itemize}

This chapter is broken up into the following sections, each of which deals with a particular graphical challenge.  This is not an exhaustive or exclusive categorisation, and there are many other possible ways to break up graphics into different categories.  Many geoms can be used for many different purposes, especially if you are creative.  However, 

\begin{itemize}
  \item Basic plot types, \secref{sec:basics}, to produce common, ``named'' graphics.
  
  \item Displaying distributions, \secref{sec:distributions}, whether continuous or discrete, 1d or 2d, joint or conditional, with histograms, density plots, boxplots and other creative combinations.
  
  \item Dealing with overplotting, \secref{sec:overplotting} is a challenge for large data.

  \item Surface plots, \secref{sec:surface}, display 3d surfaces in 2d, with imageplots, contours and other variations.

  \item Statistical summaries, \secref{sec:summary}.

  \item Revealing uncertainty and showing intervals, \secref{sec:uncertainty}.

  % \item Connecting related observations, \secref{sec:connecting}.

  \item Annotating a plot, \secref{sec:annotating}.

  \item Weighted data, \secref{sec:weighting}.
  
  % The lattice book also has
  %   * visualising multiway tables
\end{itemize}

The examples in this section use a mixture of {\tt ggplot()} and {\tt qplot()} calls, reflecting real life use.  If you need a reminder on how to translate between the two, see Appendix~\ref{sec:qplot-ggplot}.  The examples do not go into much depth, but hopefully if you flick through this chapter, you'll be able to see a plot that looks like the one you're trying to create.

\section{Overall strategy}
\label{sec:strategy}

Touch on strategies for creating a graphic

It is useful to think about the purpose of each layer before it is added.  

In general, there are three purposes for a layer:

\begin{itemize}
  \item To display the {\bf data}.  We plot the raw data for many reasons, relying on our skills at pattern detection to spot gross structure, local structure, and outliers.  This layer appears on virtually every graphic.  In the earliest stages of data exploration, it is often the only layer.

  \item To display a statistical {\bf summary} of the data. As we develop and explore models, it is useful to display the predictions from each model in the context of the data. We learn from the data summaries and we evaluate the model. A summary layer is often a part of a presentation graphic, plots produced to communicate conclusions to others. This layer is normally drawn on top of the data.

  If you review the examples in the preceding chapter, you'll see many examples of plots of data with an added layer displaying a statistical summary.

  \item To add additional {\bf metadata}, context and annotations. A metadata layer displays background context or annotations that help to give meaning to the raw data. 
  
  A map is often used as a background layer with spatial data. Background data should be rendered so that it doesn't interfere with the perception of the data, so it should normally be on the bottom layer and formatted so that it is minimally perceptible. That is, if you concentrate on it, you can see it with ease, but it doesn't jump out at you when you are casually browsing the plot.

  Some metadata, on the other hand, is intended to highlight important features of the data. If you have added explanatory labels to a couple of inflection points or outliers, then you want to render them so that they pop out at the viewer. In that case, you want this to be the very last layer drawn.

\end{itemize}


\section{Basic plot types}\label{sec:basics}

These geoms are the basic geoms used to build up many of the other geoms.  Most of these geoms are associated with a named plot: when that geom is used by itself in a plot, that plot has a special name.  These geoms are illustrated in Figure~\ref{fig:geom-basic} and described below.

Each of these geoms is two dimensional and requires both \code{x} and \code{y} aesthetics.  All understand \code{colour} and \code{size} aesthetics, and the filled geoms also understand \code{fill}.  The point geom uses \code{shape} and line and path geoms understand \code{linetype}. The geoms are used for displaying data, summaries computed elsewhere, and metadata.

\begin{itemize}
  \item \code{geom_area} draws an area plot, which is a line plot filled to the y-axis (filled lines).  Multiple groups will be stacked on top of each other.
  
  \item \code{geom_bar(stat = "identity")} makes a barchart.  By default, the bar geom automatically counts values (so is essentially a 1d geom, see \secref{sec:distributions}), so to make it use y values instead of counts, we have to specify the identity stat.  By default, multiple groups will be stacked.
  
  \item \code{geom_line} makes a line plot.  The \code{group} aesthetic determine which observations are connected, see Section~\ref{sub:grouping} for more details. \code{geom_path} is similar to a \code{geom_line}, but lines are connected in the order they appear in the data, not from left to right.  
  
  \item \code{geom_point} produces a scatterplot.
  
  \item \code{geom_polygon} draws polygons, which are filled paths.
  
  \item \code{geom_text} adds labels at the specified points.  This is the only geom in this group that requires another aesthetic: \code{label}.  It also has optional aesthetics \code{hjust} and \code{vjust} that control the horizontal and vertical position of the text; and \code{angle} which controls the rotation of the text.
  
  \item \code{geom_tile} makes a image plot or level plot.  The tiles form a regular tessellation of the plane and are typically have fill aesthetic mapped to another variable.

\end{itemize}

% FIGURE
%   LABEL: geom-basic
%   CAPTION: The basic geoms applied to the same data.  Many give rise to 
%   to named plots (from top-left to bottom-right): scatterplot, barchart,
%   line chart, area chart, path plot, labelled scatterplot, image/level 
%   plot and polygon plot.  Observe the different axis ranges for the 
%   bar, area and image plots: these geoms take up space outside the 
%   range of the data, so push the axes out.
%   GG-WIDTH: 3  GG-HEIGHT: 3 COL: 4
%   TEX-WIDTH: 0.25\textwidth
% 
% df <- data.frame(x = c(3, 1, 5), y = c(2, 4, 6), label = c("a","b","c"))
% p <- ggplot(df, aes(x, y, label = label)) + scale_x_continuous("") + scale_y_continuous("")
% p + geom_point() + opts(title = "geom_point")
% p + geom_bar(stat="identity") + opts(title = "geom_bar(stat=\"identity\")")
% p + geom_line() + opts(title = "geom_line")
% p + geom_area() + opts(title = "geom_area")
% p + geom_path() + opts(title = "geom_path")
% p + geom_text() + opts(title = "geom_text")
% p + geom_tile() + opts(title = "geom_tile")
% p + geom_polygon() + opts(title = "geom_polygon")
\input{_include/6bb6d413f9044aacca184695dd930120.tex}
% END

% Pie charts.

\section{Displaying distributions}\label{sec:distributions}

There are a number of geoms can be used to display distributions, depending on the dimensionality of the distribution, whether it is continuous or discrete, and whether you are interested in conditional or joint distributions.

For 1d continuous distributions the most important geom is the histogram.  Figure~\ref{fig:geom-1d-con} uses the histogram to display the distribution of diamond \var{depth}.  It is important to customise the parameters to find a revealing view.  If you are interested in the distribution of a continuous variable conditioned on a discrete variable, there are a few things that you can try: you could create small multiples of the histogram, \code{facets = . ~ var} with faceting; use a frequency polygon, {\tt geom = "freqpoly"}; or create a conditional density plot, {\tt position = "fill"}.  

Both the histogram and frequency polygon geom use \code{stat_bin}.  This statistic produces two output variables \code{count} and \code{density}.  The count is the default as it is most interpretable.  The density is basically the count divided by the total count, and is useful when you want to compare the shape of the distributions, not the overall size.  You will often prefer this when comparing the distribution of subsets that different sizes.

% FIGURE
%   LABEL: geom-1d-con
%   CAPTION: \Leftc, never rely on the default parameters to get a revealing
%   view of the distribution.  \Rightc, zooming in on the x axis and selecting
%   a smaller bin width reveals far more detail, {\tt xlim = c(55, 70), 
%   binwidth = 0.1}.  We can see that the distribution is slightly skew-right.  
%   Don't forget to include information about important parameters (like bin
%   width) in the caption.
% 
% qplot(depth, data=diamonds, geom="histogram")
% qplot(depth, data=diamonds, geom="histogram", xlim=c(55, 70), binwidth=0.1)
\input{_include/097b1fa8c9a922f4c2c8951180846c9d.tex}
% END

% INTERWEAVE
%   GG-WIDTH: 8 GG-HEIGHT: 3
%   TEX-WIDTH: \textwidth
% 
% qplot(depth, ..density.., data = diamonds, geom = "histogram", 
%   xlim = c(58, 68), binwidth = 0.1, facets = cut ~ ., fill = cut)
% qplot(depth, data = diamonds, geom = "histogram", 
%   xlim = c(58, 68), binwidth = 0.1, fill = cut, position = "fill", 
%   colour = I(NA))
% qplot(depth, ..density.., data = diamonds, geom = "freqpoly", 
%   xlim = c(58, 68), binwidth = 0.1, colour = cut)
\input{_include/826a070eb31dec4017b6bb1f755d1176.tex}
% END

Many of the distribution related geoms come in geom/stat pairs.  Most of these geoms are aliases: a basic geom is combined with a stat to produce the desired plot.  The boxplot may appear to be an exception to this rule, but behind the scenes \code{geom_boxplot} uses a combination of the basic bars, lines and points.

\begin{itemize}
  \item \code{geom_boxplot} = \code{stat_boxplot} + \code{geom_boxplot}: box and whisker plot, for a continuous variable conditioned by a categorical variable.  This is a useful display when the categorical variable has many distinct values, but for a few values, the techniques described above give a better view of the shape of the distribution.  This technique can also be used for continuous variables, is they are first finely binned.   Figure~\ref{fig:geom-boxplot} shows boxplots conditioned on both categorical and continuous variables.
  
  % FIGURE
  %   LABEL: geom-boxplot
  %   CAPTION: The boxplot geom can be use to see the distribution of a 
  %   continuous variable conditional on a discrete varable like cut, \leftc,
  %   or continuous variable like carat, \rightc.  For continuous variables,
  %   the group aesthetic must be set to get multiple boxplots.  Here 
  %   {\tt group = round_any(carat, 0.1, floor)} is used to get a boxplot for
  %   each 0.1 carat bin.
  % 
  % qplot(cut, depth, data=diamonds, geom="boxplot")
  % qplot(carat, depth, data=diamonds, geom="boxplot", 
  %   group = round_any(carat, 0.1, floor), xlim = c(0, 3))
  \input{_include/54d3e19c581ffe3181c63891150e026a.tex}  
  % END
  
  \item \code{geom_jitter} = \code{position_jitter} + \code{geom_point}: a crude way of looking at discrete distributions.
  
  % FIGURE
  %   LABEL: geom-jitter
  %   COL: 1 GG-WIDTH: 8 TEX-WIDTH: 0.8 \textwidth
  %   CAPTION: The jitter geom can give a crude visualisation of 2d 
  %   distributions with a discrete component.  Generally this works better
  %   for smaller datasets.  Car class vs \leftc, city mpg (continuous) and
  %   \rightc drive train (discrete).
  % 
  % qplot(class, cty, data=mpg, geom="jitter")
  % qplot(class, drv, data=mpg, geom="jitter")
  \input{_include/bc44afa44a4766a9159bec0931af6540.tex}  
  % END
  
  % \item \code{geom_quantile} = \code{stat_quantile} + \code{geom_line}: quantiles, for a continuous variable conditional on another continuous variable.  This is a continuous analogue of the boxplot. 
  % 
  % % FIGURE
  % %   LABEL: geom-quantile
  % %   CAPTION: The boxplot geom can be use to see the distribution of a 
  % %   continuous variable conditional on a, \leftc discrete varable, or
  % %   right continuous variable.  If the number of boxplots is small, 
  % %   faceted histograms will reveal finer details of the distribution.
  % % 
  % % qplot(carat, depth, data=diamonds, geom="quantile", 
  % %   xlim=c(0, 3), quantiles = c(0.05, 0.25, 0.5, 0.75, 0.95))
  % % qplot(carat, depth, data=diamonds, geom="quantile", xlim=c(0, 3), formula = y ~ factor(round_any(x, 0.5)))
  % \input{_include/7db633f75339218b80ca99f601d3132c.tex}  
  % % END
  
  \item \code{geom_density} = \code{stat_density} + \code{geom_area}: a smoothed density.  Also described in Section~\ref{sub:distribution}.  Don't use a density plot unless you know that the underlying density is continuous and unbounded, otherwise you'll get some strange artefacts. You can use the \code{adjust} parameter to make the density more or less smooth.
  
  % FIGURE
  %   LABEL: geom-density
  %   CAPTION: The density plot is a smoothed version of the histogram.  
  %   It has desirable theoretical properties, but is more difficult to 
  %   relate directly back to the data.  \Leftc a density plot of depth, 
  %   and \rightc faceted by cut.
  % 
  % qplot(depth, data=diamonds, geom="density", xlim = c(54, 70))
  % qplot(depth, data=diamonds, geom="density", xlim = c(54, 70), 
  %   fill = cut) + scale_fill_hue(alpha = 0.2)
  \input{_include/1e36666a9f8057bf5487835b543544d3.tex}  
  % END

  \item \code{geom_histogram} = \code{stat_bin} + \code{geom_bar}.  When you use a histogram, make sure to experiment with various bin widths.  Remember to try very small bin widths, right down to the resolution of the data.  
  
  \item \code{geom_freqpoly} = \code{stat_bin} + \code{geom_line}.  A frequency polygon is a histogram drawn with lines instead of bars.  Lines make it possible to display distribution of multiple subsets on the same plot.
\end{itemize}

\code{stat_qq} can be used to compare two distributions.  A plot matrix with qq plots can be used to see all pairwise comparisons of variable distributions in a dataset.

Visualising a joint 2d continuous distribution is described in the next section.

\section{Dealing with overplotting}
\label{sec:overplotting}

The scatterplot is a very important tool for assessing the relationship between a pair of continuous variables.  However, when the data is large, often points will be plotted on top of each other, obscuring the true relationship.  In extreme cases, you will only be able to see the extent of the data, and any conclusions drawn from the graphic will be suspect.  This problem is called overplotting and there are a number of ways to deal with it:

\begin{itemize}
  \item Small amounts of overplotting can sometimes be alleviated by making the points smaller, or using hollow glyphs, as shown in Figure~\ref{fig:overp-glyph}.  The data is 2000 points sampled from two independent normal distributions.

  % FIGURE
  %   FILETYPE: png
  %   LABEL: overp-glyph
  %   TEX-WIDTH: 0.4\textwidth
  %   CAPTION:  Modifying the glyph used can help with mild to moderate
  %   overplotting.  From left to right: the defaults, 
  %   {\tt shape = 1} (hollow points), {\tt size = 0.5}, and {\tt shape= "."}.   
  % 
  % df <- data.frame(x = rnorm(2000), y = rnorm(2000))
  % norm <- ggplot(df, aes(x, y))
  % norm + geom_point()
  % norm + geom_point(shape = 1)
  % norm + geom_point(size = 0.5) # 1/2 mm 
  % norm + geom_point(shape = ".") # Pixel sized
  \input{_include/1ed6c30e99aa72ba2f9e128644bd6e64.tex}  
  % END
  
  \item For larger datasets with more overplotting, you can use alpha blending to make the points transparent.  If you specify alpha as a ratio, the denominator gives the number of points that must be overplotted to give a solid colour.  In R, the lowest amount of transparency you can use is 1/256, so it will not be effective for heavily overplotting.  Figure~\ref{fig:overp-alpha} demonstrates some of these options.
    
  % FIGURE
  %   FILETYPE: png
  %   TEX-WIDTH: 0.4\textwidth
  %   LABEL: overp-alpha
  %   CAPTION: Using alpha blending to alleviate overplotting in sample data
  %   from a bivariate normal.  Alpha values from left to right: 1, 1/2, 1/5,
  %   1/10.
  % 
  % norm + geom_point()
  % norm + geom_point(colour = alpha("black", 1/2))
  % norm + geom_point(colour = alpha("black", 1/5))
  % norm + geom_point(colour = alpha("black", 1/10))
  \input{_include/90bc98a59d13dada8f15bf1d33697494.tex}  
  % END

  \item If there is some discreteness in the data, you can randomly jitter the points to alleviate overlaps.  This is particularly useful in conjunction with transparency.  By default, the amount of jitter added is 40\% of the resolution of the data, which leaves a small gap between adjacent regions. In Figure~\ref{fig:overp-jitter}, most of the points are rounded to the nearest 1, so we set a jitter width of half of that.
  
  % FIGURE
  %   FILETYPE: png
  %   COL: 3 TEX-WIDTH: 0.33\textwidth
  %   LABEL: overp-jitter
  %   CAPTION: A plot of table vs depth from the diamonds data, showing the
  %   use of jitter and alpha blending to alleviate overplotting in discrete
  %   data.  From left to right: geom point, geom jitter with default jitter,
  %   geom jitter with horizontal jitter of 0.5 (half the gap between bands) 
  %   alpha of 1/10, alpha of 1/50, alpha of 1/200.
  % 
  % td <- ggplot(diamonds, aes(table, depth)) + xlim(50, 70) + ylim(50, 70)
  % td + geom_point()
  % td + geom_jitter()
  % jit <- position_jitter(width = 0.5)
  % td + geom_jitter(position = jit)
  % td + geom_jitter(position = jit, colour = alpha("black", 1/10))
  % td + geom_jitter(position = jit, colour = alpha("black", 1/50))
  % td + geom_jitter(position = jit, colour = alpha("black", 1/200))  
  \input{_include/313aa8b0c5d6c910ed2a37929b02b948.tex}  
  % END
  
\end{itemize}

Alternatively, we can think overplotting as a 2d density estimation problem, which gives rise to two more approaches:
  
\begin{itemize}
  \item bin the points and count the number in each bin, then visualise that count in some way (the 2d generalisation of the histogram).  Breaking the plot into many small squares can produce distracting visual artefacts.  Carr \citep{carr:1987} suggests using hexagons instead, and this is implemented with \code{geom_hexagon}, using the capabilities of the {\tt hexbin} \cite{hexbin} package.  Figure~\ref{fig:overp-bin} compares square and hexagonal bins, using parameters \code{bins} and \code{binwidth} to control the number and size of the bins.
  
  % FIGURE
  %   FILETYPE: png
  %   COL: 3 TEX-WIDTH: 0.33\textwidth
  %   LABEL: overp-bin
  %   CAPTION: Binning with, top row, square bins, and bottom row, hexagonal
  %   bins. Left column uses default parameters, middle column 
  %   {\tt bins = 10}, and right column {\tt binwidth = c(0.02, 200)}.  
  %   Legends have been omitted to save space.
  % 
  % d <- ggplot(diamonds, aes(carat, price)) + xlim(1,3) +
  %   opts(legend.position = "none")
  % d + stat_bin2d()
  % d + stat_bin2d(bins = 10)
  % d + stat_bin2d(binwidth=c(0.02, 200))
  % d + stat_binhex()
  % d + stat_binhex(bins = 10)
  % d + stat_binhex(binwidth=c(0.02, 200))
  \input{_include/b77f0b3e98fd089e0ec0330d120573ea.tex}  
  % END
  
  \item A continuous analogue of this is to compute a 2d density function, with \code{stat_density2d}, and overlay contours from this distribution on the scatterplot, or display the density by itself as coloured tiles, or points with size proportional to density.  Figure~\ref{fig:overp-density} shows a few of these options.
  
  % FIGURE
  %   FILETYPE: png
  %   TEX-WIDTH: 0.4\textwidth
  %   LABEL: overp-density
  %   CAPTION: Using density estimation to model and visualise point
  %   densities.  Top, image displays of the density; bottom, point and 
  %   contour based displays.
  % 
  % d <- ggplot(diamonds, aes(carat, price)) + xlim(1,3) + 
  %   opts(legend.position = "none")
  % d + geom_point() + geom_density2d()
  % d + stat_density2d(geom="point", aes(size = ..density..), contour = FALSE)
  % 
  % d + stat_density2d(geom="tile", aes(fill = ..density..), contour = FALSE) 
  % last_plot() + scale_fill_gradient(limits=c(1e-5,8e-4))
  \input{_include/1be6bdc9e87005fc80ef34c66df8175d.tex}  
  % END
  
  \item If you are interested in the conditional distribution of y given x, then the techniques of Section~\ref{sub:distribution} will also be useful.
  
\end{itemize}

Another approach to dealing with overplotting is to add supplemental summaries to help guide the eye to the true shape of or pattern within the data.  For examples, add a smooth line showing the mean with \code{geom_smooth}, or display quantiles of the distribution with \code{geom_quantile}.  See Sections~\ref{sec:summary} for more ideas.

\section{Surface plots}
\label{sec:surface}

\ggplot currently does not support true 3d surfaces.  However, it does offer support the common tools for representing 3d surfaces in 2d: contours, coloured tiles, and points with varying sizes.  These were all illustrated in the previous section.

\begin{itemize}
  \item \code{geom_tile}: map z variable to fill colour
  \item \code{geom_contour}: useful for smoother surfaces
  \item \code{geom_point}: can map abs(z) variable to size and sign(z) to colour
\end{itemize}

You may want to look at RGL, \url{http://www.rgl.com}, for interactive 3d plots, including surfaces.

\section{Statistical summaries}
\label{sec:summary}

For continuous x, \code{stat_smooth} displays the smoothed and \code{stat_quantile} displays a smoothed set of quantiles from the distribution.  You've seen these already in Sections~\ref{sub:quantile} and~\ref{sub:smooth}.  Displaying the quantiles is advantageous because you can see much more about the shape of the distribution can just the mean.  However, it needs much more data and the functional relationship between x and y is much more limited.  The smooth geom can use any modelling method that works like \f{lm}.  This includes: generalised linear models (\f{glm}), loess (\f{lm}), generalise additive models (\f{gam}) and robust linear models (\f{rlm}), to name just a few of the many.  

For discrete x, \code{stat_summary} provides a convenient way of summarising the y values at each unique value of x.  You can use any univariate summary function, e.g. \f{mean}, \f{median}, \f{sd}, \f{var}, \f{mad}, or one of the summary functions from \code{Hmisc} described in Table~\ref{tbl:hmisc}.  These statistics work best in concert with the interval geoms, described in Section~\ref{sec:uncertainty}.  Figure~\ref{fig:stat-summary} illustrates a range of summary statistics and geoms for continuous and discrete x.

% FIGURE
%   COL: 4 TEX-WIDTH: 0.25\textwidth
%   LABEL: stat-summary
%   CAPTION: Examples of \code{stat_summary} in use.  Top, continuous
%   x with, from left to right, median and line, \f{median_hilow} and smooth, 
%   mean and line, and \f{mean_cl_boot} and smooth.  Bottom, discrete x, 
%   with, from left to right, \f{mean} and point, \f{mean_cl_normal} and 
%   error bar, \f{median_hilow} and point range, and \f{median_hilow} and 
%   crossbar.  Note that by default \ggplot displays the full range of the 
%   data, not just the results of the summary statistics.
% 
% m <- ggplot(movies, aes(year, rating))
% m + stat_summary(fun = "median", geom="line")
% m + stat_summary(fun = "median_hilow", geom="smooth")
% m + stat_summary(fun = "mean", geom="line")
% m + stat_summary(fun = "mean_cl_boot", geom="smooth")
% m2 <- ggplot(movies, aes(round(rating), log10(votes)))
% m2 + stat_summary(fun = "mean", geom="point")
% m2 + stat_summary(fun = "mean_cl_normal", geom="errorbar")
% m2 + stat_summary(fun = "median_hilow", geom="pointrange")
% m2 + stat_summary(fun = "median_hilow", geom="crossbar")

\begin{table}
  \begin{center}
  \begin{tabular}{lllp{2in}}
    \toprule
    Function & Hmisc original & Middle & Range \\
    \midrule 
    \f{mean_cl_normal} & \f{smean.cl.boot} & 
      Mean & Standard error from normal approximation \\
    \f{mean_cl_boot} & \f{smean.cl.boot} & 
      Mean & Standard error from bootstrap \\
    \f{mean_sdl} & \f{smean.sdl} & 
      Mean & Multiple of standard deviation  \\
    \f{median_hilow} & \f{smedian.hilow}  & 
      Median & Outer quantiles with equal tail areas \\
    \f{range} & --- & 
      --- & Range of the data\\
    \bottomrule
  \end{tabular}
  \end{center}
  \caption{Summary functions from \code{Hmisc} that have special wrappers to make them easy to use with \code{stat_summary}.}
  \label{tbl:hmisc}
\end{table}

You can of course also write your own summary function.  There are two ways to do this.  If you just want to produce a single output y value, your function should have argument \code{x} and return a single value.  If you want to produce y, ymin and ymax values, your function should have argument \code{data} and return a data frame with the appropriate columns.  The following example illustrates these two options:

% INTERWEAVE
% 
% iqr <- function(data, ...) {
%   data.frame(
%     ymin = quantile(data$y, 1/4), 
%     ymax = quantile(data$y, 3/4)
%   )  
% }
% m + stat_summary(fun = "iqr", geom="ribbon")
% 
% midm <- function(x) mean(x, trim = 0.5)
% m2 + 
%   stat_summary(aes(colour = "trimmed"), fun = midm, geom="point") +
%   stat_summary(aes(colour = "raw"), fun = mean, geom="point") + 
%   scale_colour_hue("Mean")

\section{Revealing uncertainty}
\label{sec:uncertainty}

If you have information about the uncertainty present in your data, possibly from a model or distributional assumptions, it is often important to visualise it.  There are four basic families of geoms that can be used for this job, depending on whether the x values are discrete or continuous, and whether or not you want to display the middle of the internal, or just the extent.  These geoms are listed in Table~\ref{tbl:interval}.  All these geoms assume that you are interested in the distribution of y conditional on x and use the aesthetics \code{ymin} and \code{ymax} to determine the range of the y values.

\begin{table}
  \begin{center}
  \begin{tabular}{lp{1.5in}p{1.5in}}
    \toprule
    X variable & Range & Range plus centre \\
    \midrule
    Continuous & \code{geom_ribbon} & \code{geom_smooth(stat="identity")} \\
    Discrete   & \code{geom_errorbar} \newline \code{geom_linerange} & \code{geom_crossbar} \newline \code{geom_pointrange}  \\
    \bottomrule
    
  \end{tabular}
  \end{center}
  \caption{Geoms that display intervals, useful for visualising uncertainty.}
  \label{tbl:interval}
\end{table}

Because there are so many different ways to calculate standard errors, the calculation is up to you.  For very simple cases, \ggplot provide some tools in the form of summary functions described in Section~\ref{sec:summary}, otherwise you will have to do it yourself.  The effects package \citep{effects} is particularly useful for extracting these values from models.  The following example fits a two-way model with interaction, and shows how to extract and visualise marginal and conditional effects.  Figure~\ref{fig:model-cat} focusses on the categorical variable colour, and Figure~\ref{fig:model-cont} focusses on the continuous variable carat.

% INTERWEAVE
% 
% d <- subset(diamonds, carat < 2.5 & rbinom(nrow(diamonds), 1, 0.2) == 1)
% d$lcarat <- log10(d$carat)
% d$lprice <- log10(d$price)
% 
% # Remove over all linear trend
% detrend <- lm(lprice ~ lcarat, data = d)
% d$lprice2 <- resid(detrend)
% 
% mod <- lm(lprice2 ~ lcarat * color, data = d)
%
% library(effects)
% color <- as.data.frame(effect("color", mod))
% both1 <- as.data.frame(effect("lcarat:color", mod))
% 
% carat <- as.data.frame(effect("lcarat", mod, default.levels = 50))
% both2 <- as.data.frame(effect("lcarat:color", mod, default.levels = 3))
\input{_include/f244db2ab0827f7ef798fe3ec4097c4b.tex}
% END

% FIGURE
%   FILETYPE: png
%   LABEL: ldata
%   CAPTION: Data transformed to remove most obvious effects.  Left, both
%   x and y axes are log10 transformed to remove non-linearity.  Right, the
%   major linear trend is removed.
% 
% qplot(lcarat, lprice, data=d, colour = color)
% qplot(lcarat, lprice2, data=d, colour = color)
\input{_include/059084969dede168a6100268bb75dfad.tex}
% END

% FIGURE
%   LABEL: model-cat
%   CAPTION: Displaying uncertaintly in model estimates for colour.  Left, 
%   marginal effect of colour, and right, conditional effects of colour for
%   different levels of carat.  Error bars show 95\% pointwise confidence 
%   intervals.
% 
% fplot <- ggplot(mapping = aes(y = fit, ymin = lower, ymax = upper))
% fplot %+% color + aes(x = color) + geom_point() + geom_errorbar()
% fplot %+% both2 + 
%   aes(x = color, colour = lcarat, group = interaction(color, lcarat)) +
%   geom_errorbar() + geom_line(aes(group=lcarat)) +
%   scale_colour_gradient(low=muted("red"), high=muted("blue"))
\input{_include/95b1b47d48f01c7c43a9f2a33081b680.tex}
% END

% FIGURE
%   LABEL: model-cont
%   CAPTION: Displaying uncertaintly in model estimates for carat.  Left, 
%   marginal effect of carat, and right, conditional effects of carat for
%   different levels of colour.  Bands show 95\% point-wise confidence
%   intervals
% 
% fplot %+% carat + aes(x = lcarat) + geom_smooth(stat="identity")
% 
% ends <- subset(both1, lcarat == max(lcarat))
% fplot %+% both1 + aes(x = lcarat, colour = color) +
%  geom_smooth(stat="identity") + 
%  scale_colour_hue() + opts(legend.position = "none") +
%  geom_text(aes(label = color, x = lcarat + 0.02), ends)
\input{_include/c91e8f027baae107d124810a4bc33737.tex}
% END

Note, when captioning such figures, you need to carefully describe the nature of the confidence intervals, and whether or not it is meaningful to look at the overlap.  

% \section{Connecting related observations}
% \label{sec:connecting}
% 
% It is often useful to connect related observations explicitly with a line.  This is the basis of the parallel coordinates plot \citep{inselberg:1985,wegman:1990}, the m-n plot \citep{diaconis:1983}, time series plots, and profile plots.  
%
% Grouping particularly important.  Revisit Section~\ref{sub:grouping}

\section{Annotating a plot}
\label{sec:annotating}

When annotating your plot with additional labels, the important thing to remember is that these annotations are just extra data.  There are two basic ways to add annotations: one at a time, or many at once.

Adding one at a time works best for small numbers of annotations with varying aesthetics.  You just set all the values to the give the desired properties.  If you have multiple annotations with similar properties, it may make sense to put them all in a data frame and add them at once.  The example below demonstrates both approaches by adding information about presidents to economic data.

% INTERWEAVE
% 
% (unemp <- qplot(date, unemploy, data=economics, geom="line"))
% 
% load("~/documents/data/08-presidents/presidents.rdata")
% presidents <- presidents[-(1:3), ]
% 
% yrng <- range(economics$unemploy)
% xrng <- range(economics$date)
% unemp + geom_vline(aes(intercept = start), data = presidents)
% unemp + geom_rect(aes(xmin = start, xmax = end, y = NULL, x = NULL, 
%   fill = party), ymin = rng[1], ymax = rng[2], data=presidents) +
%   scale_fill_manual(values = alpha(c("blue", "red"), 0.2))
% last_plot() + geom_text(aes(x = start, y = rng[1], label = name), 
%   data = presidents, size = 3, hjust = 0, vjust = 0)
% caption <- paste(strwrap("Unemployment rates in the US have varied a 
%   lot over the years", 40), collapse="\n")
% last_plot() + geom_text(aes(x = xrng[2], y = yrng[2], label = caption), 
%   data=data.frame(), hjust = 1, vjust = 1, size = 4)
% 
% highest <- subset(economics, unemploy == max(unemploy))
% unemp + geom_point(colour = alpha("red", 0.5), data = highest, size = 3)

\begin{itemize}
  \item \code{geom_text} for adding textual annotations.  Most plots will not benefit from adding text to every single observation on the plot.  However, pulling out just a few observations (using subset) can be very useful.  Typically you will want to label outliers or other important points.
  
  \item \code{geom_vline}, \code{geom_hline}: add vertical or horizontal lines to a plot
  
  \item \code{geom_abline}: add lines with arbitrary slope and intercept to a plot
  
  \item \code{geom_rect} for highlighting interesting regions of the plot.  \code{geom_rect} has aesthetics xmin, xmax, ymin and ymax.
  
  \item \code{geom_line}, \code{geom_path} and \code{geom_segment} for adding lines.  All these geoms have an \code{arrow} parameter, which allows you to place an arrow head on the line.  You create arrowheads with the \f{arrow} function, which has arguments \code{angle}, \code{length}, \code{ends} and \code{type}.
  
\end{itemize}

See also Section~\ref{sec:adding_annotation} for ways to add more general types of annotation using grid graphics.

\section{Weighted data}
\label{sec:weighting}

% The {\tt weight} aesthetic is also useful when you have weighted data.  All ggplot2 statistics know how to correctly deal with (WHAT TYPE OF WEIGHTS?) weights, which makes plotting your weighted data easy.  For a more comprehensive description of plotting weights, see ``Weight and see''.

When you have aggregated data where each row in the dataset represents multiple observations, you need some way to take into account the weighting variable.  Since there are no variables appropriate for weighting in the diamonds data, we will use some data collected on Midwest states in the 2000 US census.  The data consists mainly of percentages (eg. percent white, percent below poverty line, percentage with college degree) and some information for each county (area, total population, population density).

There are few different things we might want to weight by: 

\begin{itemize}
  \item nothing, to look at county numbers
  \item total population, to work with absolute numbers
  \item area, to investigate geographic effects
\end{itemize}

\noindent The choice of a weighting variable profoundly effects what we are looking at in the plot and the conclusions that we will draw.  There are two aesthetic attributes that can be used to adjust for weights.  Firstly, for simple geoms like lines and points, you can make the size of the grob proportional to the number of points, using the {\tt size} aesthetic, as follows:

% INTERWEAVE
%
% midwest <- read.csv("~/Documents/weight-and-see/midwest.csv")
% qplot(percwhite, percbelowpoverty, data=midwest)
% qplot(percwhite, percbelowpoverty, data=midwest, size=poptotal) + scale_area()
% qplot(percwhite, percbelowpoverty, data=midwest, size=area) + scale_area()
\input{_include/d2fb1822bbae9e723323390a9ab3159b.tex}
% END

For more complicated grobs which involve some statistical transformation, we specify weights with the {\tt weight} aesthetic.  These weights will be passed on to the statistical summary function.  Weights are supported for every case where it makes sense: smoothers, quantile regressions, box plots, histograms, and density plots.  You can't see this weighting variable directly, and it doesn't produce a legend, but it will change the results of the statistical summary.  Figure~\ref{fig:weight-lm} shows how weighting by population density effects the relationship between percent white and percent below the poverty line.

% FIGURE
%   LABEL: weight-lm
%   CAPTION: \leftc A line of best fit unweighted by population size, and 
%   \rightc weighted by population size.
%
% lm_smooth <- geom_smooth(method = lm, size = 1)
% qplot(percwhite, percbelowpoverty, data = midwest) + lm_smooth 
% qplot(percwhite, percbelowpoverty, data = midwest, 
%   weight = popdensity, size = popdensity) + lm_smooth
\input{_include/f3af97ae7cbaf4a40298e3076c51349c.tex}
% END

When we weight a histogram or density plot by total population, we change from looking at the distribution of the number of counties, to the distribution of the number of people.  Figure~\ref{fig:weight-hist} shows the difference this makes for a histogram of the percentage below the poverty line.

% FIGURE
%   LABEL: weight-hist
%   CAPTION: The different between an \leftc unweighted and \rightc weighted
%   histogram.  The unweighted histogram shows number of counties, while the
%   weighted histogram shows population
%
% qplot(percbelowpoverty, data=midwest, geom="histogram", binwidth=1)
% qplot(percbelowpoverty, data=midwest, geom="histogram", weight=poptotal, binwidth=1) + scale_y_continuous("population")
\input{_include/884f62b6543c9c28436ac166c8f86a14.tex}
% END

\input{_footer.tex}
