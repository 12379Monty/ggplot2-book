\input{_header.tex}

\chapter{Mastering the grammar}
\label{cha:mastery}

% Introduction to the components of the grammar
% Introduction to the data structure
% Roadmap for next few chapters


\section{Introduction}\label{sec:introduction}

You can choose to use just {\tt qplot}, without any understanding of the underlying grammar, but you will not be able to use the full power of ggplot.  By learning more about the grammar, and the components that make it up, you will be able to create a wider range of plots, as well as being able to combine multiple sources of data, and customise to your heart's content.

This chapter describes the theoretical basis of ggplot2: the layered grammar of graphics, a based based on Wilkinson's grammar of graphics \citep{wilkinson:2006}.  The next chapters then describe parts of the grammar in more detail: layers (geoms and stats), scales, and positioning (coordinate systems, faceting and position adjustments),

You may want to skip this chapter in a first reading of the book, and then come back to it when you want a deeper understanding of how all the pieces fit together.

This chapter begins by describing in detail a simple plot is drawn.  We'll start with a simple scatterplot, and then grow progressively more complicated, by transforming the axes and adding a smooth line.

\section{Building a scatterplot}
\label{sec:building_a_plot}

When creating a plot we start with data.  Consider the mammal's sleep dataset illustrated in Table~\ref{tbl:sleep}.  This is included in \ggplot and is called \code{msleep}.  The data records the brain and body weights, sleep times, and a few other variables for 83 mammals.   You can find out more about the data by typing \code{?msleep} within R. 

% msleep <- read.csv("~/Documents/data/08-msleep/msleep.csv")
% animals <- sort(c("African elephant", "Pilot whale", "Human", "Horse", "Domestic cat"))
% msel <- subset(msleep, name %in% animals)


% source("latex.r")
% tabulate(msel[, c("name", "order", "brainwt", "bodywt", "awake", "sleep_rem")])

\begin{table}
  \begin{center}
  \begin{tabular}{llrrp{2cm}p{2cm}}
    \toprule
    Animal & Order & Brain weight & Body weight & Awake (hours) & Rem sleep (hours) \\
    \midrule
    Domestic cat     & Carnivora      & 0.0256 &    3.3 & 11.50 & 3.2\\
    Horse            & Perissodactyla & 0.6550 &  521.0 & 21.10 & 0.6\\
    Human            & Primates       & 1.3200 &   62.0 & 16.00 & 1.9\\
    African elephant & Proboscidea    & 5.7120 & 6654.0 & 20.70 & ---\\
    Pilot whale      & Cetacea        &    --- &  800.0 & 21.35 & 0.1\\
    \bottomrule
  \end{tabular}
  \end{center}
  \caption{Five mammals from the \code{msleep} data set.  Missing values are illustrated with a ---.  }
  \label{label}
\end{table}


Let's draw a scatterplot of \var{brainwt} vs. \var{bodywt}.  What exactly is a scatterplot?  One way to describe it is has a point for each observation, positioned horizontally according to the value of \var{brainwt}, and vertically according to \var{bodywt}.  The first step in making this plot is to create a new dataset which reflects the mapping of $x$-position to \var{brainwt}, and $y$-position to \var{bodywt} and colour to \var{diet}.  $x$-position, $y$-position and colour are all aesthetics, things that can be perceived on the graphic. We will also remove all other variables that do not appear in the plot.  This is shown in Table \ref{tbl:mapping}.

\begin{table}[ht]
	\begin{center}
	\begin{tabular}{r|r|r}
		$x$ & $y$ & $colour$\\
		\hline
		2 & 4 & a\\
		1 & 1 & a\\
		4 & 15 & b\\
		9 & 80 & b
	\end{tabular}
	\end{center}
	\caption{Sample rows from \code{msleep} with variables named according to the aesthetic that they use.}
	\label{tbl:mapping}
\end{table}

We can create many different types of plots using this data.  For example, if we were to draw lines instead of points we would get a line plot.  If we used bars, we'd get a bar plot.  Bars, lines and points are all examples of geometric objects.  

These values currently have no meaning to the computer.  We need to convert them from being in data units (e.g.\ kg) to physical units (e.g.\ pixels), that the computer knows how to display.  (The way that these physical units can been specified in R is described in Appendix~\ref{chp:specification}). Converting position is easy for this example which has linear scales and a Cartesian coordinate system - we just need a linear mapping from the range of the data to $[0, 1]$.  (We can use $[0, 1]$ instead of exact pixels because the drawing system that \ggplot uses, \code{grid}, will take care of that for us.)

\[ \frac{x - \min(x)}{\mbox{range}(x)}  \] 

It is the coordinate system that performs this mapping, and for other coordinate systems the mapping is more complex (and may depend on both x and y variables), but in all cases is mapped to range $[0, 1]$.

The process for mapping the colour is a little more complicated, and here the scale does all of the work.  A scale needs to know the range and the domain of the data.  The default scale in \ggplot maps colour to evenly space hues on a colour wheel.


\begin{table}[ht]
	\begin{center}
	\begin{tabular}{r|r|r}
		$x$ & $y$ & $colour$\\
		\hline
		25 & 11 & red\\
		0 & 0 & red \\
		75  & 53 & blue \\
		200 & 300 & blue
	\end{tabular}
	\end{center}
	\caption{Simple dataset with variables mapped into aesthetic space.}
	\label{tbl:scaled}
\end{table}

In general, there is another step that we've skipped in this simple example: a statistical transformation.  Here we are using the identity transformation, but there are many others that are useful, such as binning or aggregating.  Statistical transformations, or stats, are described in detail in Section~\ref{sub:stats}.

Finally, we need to render this data to create the graphical objects that are displayed on the screen.  To create a complete plot we need to combine graphical objects from three sources: the \emph{data}, represented by the point geom; the \emph{scales and coordinate system}, which generates axes and legends so that we can read values from the graph; and the \emph{plot annotations}, such as the background and plot title.  These components are shown in Figure~\ref{fig:simple-exploded}.  Combining and displaying these graphical objects produces the final plot, as in Figure~\ref{fig:simple}.

\begin{figure}[htbp]
	\centering
	\caption{Graphics objects produced by (from left to right): geometric objects, scales and coordinate system, plot annotations.}
	\label{fig:simple-exploded}
\end{figure}

\begin{figure}[htbp]
	\centering
	\caption{The final graphic, produced by combining the pieces in Figure~\ref{fig:simple-exploded}.}
	\label{fig:simple}
\end{figure}

\subsection{A more complicated plot}\label{sec:how_to_build_a_more_complicated_plot} 

Now that you are acquainted with drawing a simple plot, we will create a more complicated plot.  The big difference with this plot is that we'll use faceting.  Faceting is also known as conditioning, trellising and latticing, and produces small multiples showing different subsets of the data.  If we facet the previous plot by $D$ we will get a plot that looks like Figure~\ref{fig:complex}, where each value of $D$ is displayed in a different panel.

\begin{figure}[htbp]
	\centering
	\caption{A more complicated plot, which is faceted by variable $D$.  Here the faceting uses the same variable that is mapped to colour so that there is some redundancy in our visual representation.  This allows us to easily see how the data has been broken into panels.}
	\label{fig:complex}
\end{figure}

Faceting splits the original dataset into a dataset for each subset, so the data that underlies Figure~\ref{fig:complex} looks like Table \ref{tbl:complex}.

\begin{table}[ht]
	\centering
	\begin{tabular}{r|r|r|r}
		& $x$ & $y$ & $colour$\\
		\hline
		a & 2 & 4 & red\\
		a & 1 & 1 & red\\
		\hline \hline
		b & 4 & 15 & blue\\
		b & 9 & 80 & blue
	\end{tabular}

	\caption{Simple dataset faceted into subsets.}
	\label{tbl:complex}
\end{table}

The first steps of plot creation proceed as before, but new steps are necessary when we get to the scales.   Scaling actually occurs in three parts: transforming, training and mapping. 

\begin{itemize}
	\item  Scale transformation occurs before statistical transformation so that statistics are computed on the scale-transformed data.  This ensures that a plot of $log(x)$ vs $log(y)$ on linear scales looks the same as $x$ vs $y$ on log scales.  See Section~\ref{sub:transformation} for more details. Transformation is only necessary for non-linear scales, because all statistics are location-scale invariant.

	\item After the statistics are computed, each scale is trained on every faceted dataset (a plot can contain multiple datasets, e.g.\ raw data and predictions from a model).  The training operation combines the ranges of the individual datasets to get the range of the complete data.  If scales were applied locally, comparisons would only be meaningful within a facet.  This is shown in Table \ref{tbl:complex-incorrect}.

  % FIXME
	\item Finally the scales map the data values into aesthetic values.  This gives Table \ref{tbl:complex-mapping} which is essentially identical to Table \ref{tbl:mapping} apart from the structure of the datasets.  Given that we end up with an essentially identical structure you might wonder why we don't simply split up the final result.  There are several reasons for this.  It makes writing statistical transformation functions easier, as they only need to operate on a single facet of data, and some need to operate on a single subset, for example, calculating a percentage.  Also, in practice we may have a more complicated training scheme for the position scales so that different columns or rows can have different $x$ and $y$ scales.  
	
\end{itemize}

\begin{table}[ht]
	\centering
	\begin{tabular}{r|r|r|r}
		& $x$ & $y$ & $colour$\\
		\hline
		a & 200 & 300 & red\\
		a & 0 & 0 & red\\
		\hline \hline
		b & 0 & 0 & red\\
		b & 200 & 300 & red
	\end{tabular}

	\caption{Local scaling, where data are scaled independently within each facet. Note that each facet occupies the full range of positions, and only uses one colour.  Comparisons across facets are not necessarily meaningful.}
	\label{tbl:complex-incorrect}
\end{table}

\begin{table}[ht]
	\centering
	\begin{tabular}{r|r|r|r}
		& $x$ & $y$ & $colour$\\
		\hline
		a & 25 & 11 & red\\
		a & 0 & 0 & red\\
		\hline \hline
		b & 75 & 53 & blue\\
		b & 200 & 300 & blue
	\end{tabular}

	\caption{faceted data correctly mapped to aesthetics.  Note the similarity to Table \ref{tbl:scaled}.}
	\label{tbl:complex-mapping}
\end{table}

\subsection{Summary}\label{sec:the_grammar}

In the examples above, we have seen some of the components that make up a plot:

\begin{itemize}
  \item data and aesthetic mappings,
  \item geometric objects, 
  \item scales,
  \item and facet specification.
\end{itemize}

\noindent We have also touched on two other components: 

\begin{itemize}
  \item statistical transformations,
  \item and the coordinate system.
\end{itemize}

\noindent Together, the data, mappings, statistical transformation and geometric object form a layer.  A plot may have multiple layers, for example, when we overlay a scatterplot with a smoothed line.

\section{Components of the layered grammar}

To be precise, the layered grammar defines the components of a plot as:

\begin{itemize}
  \item A default dataset and set of mappings from variables to aesthetics.
  \item One or more layers, each composed of a geometric object, a statistical transformation, and a position adjustment, and optionally, a dataset and aesthetic mappings.
  \item One scale for each aesthetic mapping used.
  \item A coordinate system.
  \item The facet specification.
\end{itemize}


The layer component is particularly important as it determines the physical representation of the data, with the combination of stat and geom defining many familiar named graphics: the scatterplot, histogram, contourplot, and so.  In practice, many plots have (at least) three layers: the data, context for the data, and a statistical summary of the data.  For example, to visualise a  spatial point process, we might display the points themselves, a map giving some context to the locations of points, and contours of a 2d density estimate.

This grammar is useful for both the user and the developer of statistical graphics.  For the user, it makes it easier to iteratively update a plot, changing a single feature at a time.  The grammar is also useful because it suggests the high level aspects of a plot that \emph{can} be changed, giving us a framework to think about graphics, and hopefully shortening the distance from mind to paper.  It also encourages the use of graphics customised to a particular problem, rather than relying on generic named graphics.

For the developer, it makes it much easier to add new capabilities. You only need to add the one component that you need, and continue to use the all the other existing components.  For example, you can add a new statistical transformation, and continue to use the existing scales and geoms.  It is also useful for discovering new types of graphics, as the grammar effectively defines the parameter space of statistical graphics.

\subsection{Layers}

Layers are responsible for creating the objects that we perceive on the plot.  A layer is composed of four parts:  

\begin{itemize}
	\item data and aesthetic mapping,
	\item a statistical transformation (stat), 
	\item a geometric object (geom)
	\item and a position adjustment.
\end{itemize}

\noindent These parts are described in detail below.

Usually all the layers on a plot have something in common, which is typically that they are different views of the same data, e.g.\ a scatterplot with overlaid smoother.  


\subsubsection{Data and mapping}\label{sub:data_and_mapping} 

Data is obviously a critical part of the plot, but it is important to remember that it is independent from the other components: we can construct a graphic that can be applied to multiple datasets. Data is what turns an abstract graphic into a concrete graphic.

Along with the data, we need a specification of which variables are mapped to which aesthetics.  For example, we might map weight to x position, height to y position and age to size.  The details of the mapping are described by the scales, Section~\ref{sec:scales}.  Choosing a good mapping is crucial for generating a useful graphic, as described in Section~\ref{sec:strategy}.

\subsubsection{Statistical transformation}\label{sub:stats} 

A statistical transformation, or {\bf stat}, transforms the data, typically by summarising it in some manner.  For example, a useful stat is the smoother, which calculates the mean of y, conditional on x, subject to some restriction that ensures smoothness. Table \ref{tbl:statistics} lists some of the stats available in ggplot2.  To make sense in a graphic context a stat must be location-scale invariant: $\mbox{f}(x + a) = \mbox{f}(x) + a$ and $\mbox{f}(b \cdot x) = b \cdot \mbox{f}(x)$.  This ensures that the transformation is invariant under translation and scaling, which are common operations on a graphic.

A stat takes a dataset as input and returns a dataset as output, and so a stat can add new variables to the original dataset.  It is possible to map aesthetics to these new variables.  For example, one way to describe a histogram is as a binning of a continuous variable, plotted with bars whose height is proportional to the number of points in each bin, as described in Section \ref{sub:histogram}.  Another useful example is mapping the size of the lines in a contour plot to the height of the contour.

The actual statistical method used by a stat is conditional on the coordinate system.  For example, a smoother in polar coordinates should use circular regression, and in 3d should return a 2d surface rather than a 1d curve.  However, many statistical operations have not been derived for non-Cartesian coordinates and we so we generally fall back to Cartesian coordinates for calculation, which, while not strictly correct, will normally be a fairly close approximation.  

\begin{table}
	\begin{center}
	\begin{tabular}{l|l}
	Name & Description \\
	\hline
	bin & Divide continuous range into bins, and count number of points in each\\ 
	boxplot & Compute statistics necessary for boxplot\\
	contour & Calculate contour lines\\
	density & Compute 1d density estimate \\
	identity & Identity transformation, $f(x) = x$ \\
	jitter & Jitter values by adding small random value \\
	qq & Calculate values for quantile-quantile plot \\
	quantile & Quantile regression\\
	smooth & Smoothed conditional mean of $y$ given $x$ \\
	summary & Aggregate values of $y$ for given $x$ \\
	sortx & Sort values in order of ascending $x$\\
	unique & Remove duplicated observations\\
	\end{tabular}
	\end{center}
	\caption{Some statistical transformations provided by ggplot2.  The user is able to supplement this list in a straight forward manner.}
	\label{tbl:statistics}
\end{table}

\subsubsection{Geometric object}\label{sub:geometric-objects} 

Geometric objects, or {\bf geom}s for short, control the type of plot that you create.  For example, using a point geom will create a scatterplot, while using a line geom will create a line plot.  We can classify geoms by their dimensionality:

\begin{itemize}
	\item 0d: point, text
	\item 1d: path, line (ordered path)
	\item 2d: polygon, interval
\end{itemize}

Geometric objects are an abstract component and can be rendered in different ways. Figure~\ref{fig:interval} illustrates four possible renderings of the interval geom. 

\begin{figure}[htbp]
	\centering
	\caption{Four representations of an interval geom.  From left to right: as a bar, as a line, as a error bar, and (for continuous x) as a ribbon.}
	\label{fig:interval}
\end{figure}

Geoms are mostly general purpose, but do require certain outputs from a statistic.  For example, the boxplot geom requires the position of the upper and lower fences, upper and lower hinges, the middle bar and the outliers. Any statistic used with the boxplot needs to provide these values. 

Every geom has a default statistic, and every statistic a default geom.  For example, the bin statistic defaults to using the bar geom to produce a histogram.  Over-riding these defaults will still produce valid plots, but they may violate graphical conventions.

Each geom can only display certain aesthetics.  For example, a point geom has position, colour, and size aesthetics.  A bar geom has all those, plus height, width and fill colour.  Different parameterisations may be useful.  For example, instead of location and dimension, we could parameterise the bar with locations representing the four corners.  Parameterisations which involve dimension (e.g.\ height and width) only make sense for Cartesian coordinate systems.  For example, height of a bar geom in polar coordinates corresponds to radius of a segment.  For this reason location based parameterisations are used internally.  

\subsubsection{Position adjustment}

Sometimes we need to tweak the position of the geometric elements on the plot, when otherwise they would obscure each other.  This is most common in bar plots, where we stack or dodge (place side-by-side) the bar to avoid overlaps.  In scatterplots with few unique x and y values, we sometimes randomly jitter \citep{chambers:1983} the points to reduce overplotting.  

\subsection{Scales}\label{sec:scales}

A {\bf scale} controls the mapping from data to aesthetic attributes, and so we need one scale for each aesthetic property used in a layer.  Scales are common across layers to ensure a consistent mapping from data to aesthetics.  Some scales are illustrated in Figure~\ref{fig:scales}.

\begin{figure}[htbp]
	\centering
	\caption{Examples of four scales from ggplot2.  From left to right: continuous variable mapped to size and colour, discrete variable mapped to shape and colour.  The ordering of scales seems upside-down, but this matches the labelling of the $y$-axis: small values occur at the bottom.}
	\label{fig:scales}
\end{figure}

% sc <- ScaleSize$new()
% sc$train(1:10)
% pdf("2-scale-size.pdf", height=2, width=1); grid.draw(sc$guide_legend()); dev.off()
% sc <- ScaleColourContinuous$new()
% sc$train(1:10)
% pdf("2-scale-colour.pdf", height=2, width=1); grid.draw(sc$guide_legend()); dev.off()
% sc <- ScaleColourHue$new()
% sc$train(factor(letters[1:5]))
% pdf("2-scale-colour2.pdf", height=2, width=1); grid.draw(sc$guide_legend()); dev.off()
% sc <- ScaleShape$new()
% sc$train(factor(letters[1:5]))
% pdf("2-scale-shape.pdf", height=2, width=1); grid.draw(sc$guide_legend()); dev.off()

%(\citet{cleveland:1993a} uses scale instead of data and physical instead of aesthetic)

A scale is a function, and its inverse, along with a set of parameters.  For example, the colour gradient scale maps a segment of the real line to a path through a colour space.  The parameters of the function define whether the path is linear or curved, which colour space to use (eg. LUV or RGB), and the start and end colours.  

The inverse function is used to draw a guide so that you can read values from the graph.  Guides are either axes (for position scales) or legends (for everything else).  Most mappings have a unique inverse (i.e\. the mapping function is one-to-one), but many do not.  A unique inverse makes it possible to recover the original data, but this is not always desirable if we want to focus attention on a single aspect.

Scales typically map from a single variable to a single aesthetic, but there are exceptions.  For example, we can map one variable to hue and another to saturation, to create a single aesthetic, colour.  We can also create redundant mappings, mapping the same variable to multiple aesthetics.  This is particularly useful when producing a graphic that works in both colour and black and white. 

\subsection{Coordinate system}\label{sec:coordinate_systems}

A coordinate system, {\bf coord} for short, maps the position of objects onto the plane of the plot.  Position is often specified by two coordinates $(x, y)$, but could be any number of coordinates.  The Cartesian coordinate system is the most common coordinate system for two dimensions, while polar coordinates and various map projections are used less frequently.  For higher dimensions, we have parallel coordinates (a projective geometry), mosaic plots (a hierarchical coordinate system) and linear projections onto the plane.

Coordinate systems affect all position variables simultaneously and differ from scales in that they also change the appearance of the geometric objects.  For example, in polar coordinates, bar geoms look like segments of a circle.  Additionally, scaling is performed before statistical transformation, while coordinate transformations occur afterward.  The consequences of this are shown in Section \ref{sub:transformation}.

Coordinate systems control how the axes and grid lines are drawn.  Figure~\ref{fig:coord} illustrates three different types of coordinate systems.  Very little advice is available for drawing these for non-Cartesian coordinate systems, so a lot of work needs to be done to produce polished output.

% x1 <- c(1,10)
% y1 <- c(1, 5)
% old <- ggopt(grid.colour="black", grid.fill="white", border.colour ="black")
% p <- qplot(x1, y1, geom="blank")
% p
% ggsave(file="2-coord-cartesian.pdf", width=8, height=6)
% p + coord_polar()
% ggsave(file="2-coord-polar.pdf", width=6, height=6)
% p + coord_trans(y="log10")
% ggsave(file="2-coord-log.pdf", width=8, height=6)
% ggtheme(old)

\begin{figure}[htbp]
	\centering
	\caption{Examples of axes and grid lines for three coordinate systems: Cartesian, semi-log and polar. The polar coordinate system illustrates the difficulties associated with non-Cartesian coordinates: it is hard to draw the axes correctly!}
	\label{fig:coord}
\end{figure}

\subsection{Faceting}\label{sec:faceting}

There is also another thing that turns out to be sufficiently useful that we should include it in our general framework: faceting (also known as conditioned or trellis plots). This makes it easy to create small multiples of different subsets of an entire dataset. This is a powerful tool when investigating whether patterns hold across all conditions.  The faceting specification describes which variables should be used to split up the data, and how they should be arranged in a grid.



\section{Data structures}
\label{sec:data_structures}

These principles are encoded as data structures in a fairly straightforward way.

There are two ways to create these plot objects: all at once with \f{qplot}, as shown in the previous chapter, or piece-by-piece with \f{ggplot} and layer functions, as described in the next chapter.

One thing to note is that all ggplot2 objects (with the exception of the main plot object) are proto objects.  Proto is a package which implements the prototype-style of object-oriented programming.  There are some major differences between this and the typical S3 or S4 style of OO in R, but the good news is that you only need to worry about them if you want to develop your own extensions to ggplot2.  For everyday use, the proto objects are hidden behind a facade which makes them act like normal R objects.

{\tt str} to see full structure (it can be large!)

{\tt summary} briefly describes the structure of the plot

Data stored inside the plot - if you change the data outside of the plot, and then redraw a saved plot, it will not be updated.  Consequence of R copying semantics.

\input{_footer.tex}

% \section{What is a plot?}
% \label{sec:what_is_a_plot}
% 
% One way to think about the grammar of graphics is as a question: what is a plot?  The grammar answers this by describing a plot as a collection of independent components, each describing an independent part of the plot.  There are three basic things we need for a plot: one or more layers, scales to map variables from data space to visual space, and a coordinate system.  These are described below.
% 
% \begin{itemize}
%   \item One or more layers.  A layer is composed of data and a description of which data variables should be mapped to which aesthetic properties, a geometric object, and a statistical transformation:
%   
%   \begin{itemize}
%     \item Data is obviously the most important part, and it is what you provide.  This is what you are displaying visually to aid communication or analysis.  You also need to describe how variables in the dataset are mapped to visual properties.  For example, in Figure 2.X we mapped diamond price to y position, carat to y position and colour to colour.  Because the data and aesthetic mapping set is usually the same in most layers, these can also be set as defaults at the plot level.
%     
%     \item {\bf Geoms}, short for geometric objects, control the type of plot that you create.  For example, using a point geom will create a scatterplot, while using a line geom will create a line plot.
% 
%     \item {\bf Stats}, or statistical transformations, reduce or augment the data in a statistical manner.  For example, a useful stat is the smoother, which shows the mean of y, conditional on x.  Another common stat is the binner, which bins data in to bins.   Every geom has a default statistic, and every statistic a default geom.  For example, the bin statistic has defaults to using the bar geom to produce a histogram.
% 
%     \item {\bf Position adjustment}
%   \end{itemize}
% 
%   \item A scale for all the aesthetic properties.  {\bf Scales} control the mapping from data attributes to aesthetic attributes.  They also provide an inverse mapping in the form of a guide, an axis or legend, which facilitates reading the final graphic.  Aesthetic attributes are things like position, size, colour---anything that you can perceive.  The function that maps data to aesthetic attributes is a scale. It takes values in data space (continuous or categorical) and maps them into an aesthetic space (eg. colour, size, shape).  A scale also provides guides to convert back from the aesthetic attribute to the original data.  Guides are either axes (for position) or legends (for everything else)
% 
%   \item A coordinate system.  A {\bf coord}, or coordinate systems, maps the position of objects on to the plane of the plot.  Typically we will use the cartesian coordinate system, but sometimes others are useful.
% \end{itemize}
% 
% There is also another thing that turns out to be sufficiently useful that we should include it in our general framework: faceting (also known as conditioned or trellis plots). This allows us to easily create small multiples of different subsets of an entire dataset. This is a powerful tool when investigating whether patterns hold across all conditions.
